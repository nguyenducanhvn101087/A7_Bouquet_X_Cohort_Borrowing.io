<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Anh Nguyen Duc" />


<title>Bouquet - Borrowing X-cohort</title>

<script src="1_Bouquet_Borrowing_X_Cohort_files/header-attrs-2.14/header-attrs.js"></script>
<script src="1_Bouquet_Borrowing_X_Cohort_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="1_Bouquet_Borrowing_X_Cohort_files/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="1_Bouquet_Borrowing_X_Cohort_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="1_Bouquet_Borrowing_X_Cohort_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="1_Bouquet_Borrowing_X_Cohort_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="1_Bouquet_Borrowing_X_Cohort_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="1_Bouquet_Borrowing_X_Cohort_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="1_Bouquet_Borrowing_X_Cohort_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="1_Bouquet_Borrowing_X_Cohort_files/navigation-1.1/tabsets.js"></script>
<link href="1_Bouquet_Borrowing_X_Cohort_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="1_Bouquet_Borrowing_X_Cohort_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">



<h1 class="title toc-ignore">Bouquet - Borrowing X-cohort</h1>
<h4 class="author">Anh Nguyen Duc</h4>
<h4 class="date">04 March, 2023</h4>

</div>


<div
id="winbugs-model-for-binary-exnex-model-with-stochastic-mixture-weights"
class="section level2" number="0.1">
<h2><span class="header-section-number">0.1</span> WinBUGs model for
binary EXNEX model with stochastic mixture weights</h2>
<p>This is based on section 5.3 of <a
href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf"
class="uri">https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf</a></p>
<p>Original paper is <a
href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/pst.1730"
class="uri">https://onlinelibrary.wiley.com/doi/epdf/10.1002/pst.1730</a></p>
<pre class="r"><code>### Model definition 
binary_exnex_model2 &lt;- function() {
## Data to be specify in the input
#-------------------------------------------------------------------------------

# Nexch        - number of exchangeable components
# Nmix         - number of mixture weights and must be Nexch+1
# Nstrata      - number of strata e.g. studies or cohort (in platform trial)
# pMix         - vector of Nmix mixture weights (summing up to 1)
# n            - vector of Nstrata elements storing patient numbers for each stratum
# r            - vector of Nstrata elements storing response numbers for each stratum
# n_fa         - vector of Nstrata elements storing patient numbers for each stratum at final analysis
# mu.mean      - vector of Nexch prior mean(s)
# mu.prec      - vector of Nexch prior precision(s)
# tau.HN.scale - scale parameter of Half-Normal prior for tau
# nex.mean     - prior mean for non-exchangeable component
# nex.prec     - prior precision for non-exchangeable component
# p.cut        - clinically relevant threshold for response rate to compare against
  
## Parameter(s) to be monitored
# p            - posterior response rate
# p.success    - posterior indicator if p &gt; p.cut
# pMix         - posterior mixture weight to test for &quot;exchangeability&quot;
# p.success_fa - posterior indicator if r_fa/n_fa &gt; p.cut
#-------------------------------------------------------------------------------
  
  # prior distributions for EX-parameters
  for (jj in 1:Nexch) {
    mu[jj] ~dnorm(mu.mean[jj],mu.prec[jj])
    prior.tau.prec[jj] &lt;- pow(tau.HN.scale[jj],-2)
    tau[jj] ~ dnorm(0,prior.tau.prec[jj]);I(0.001,)
    prec.tau[jj] &lt;- pow(tau[jj],-2)
  }
  
  # log-odds parameters under EX
  for (jj in 1:Nexch) {
    for (j in 1:Nstrata) {
      re[jj,j] ~ dnorm(0,prec.tau[jj])
      LogOdds[jj,j] &lt;- mu[jj]+re[jj,j]
    }
  }
  
  # log-odds parameters under NEX
  for (j in 1:Nstrata) {
    LogOdds[Nmix,j] ~ dnorm(nex.mean,nex.prec)
  }
  
  # latent mixture indicators:
  # exch.index: categorial 1,...,Nmix=Nexch+1
  # exch: Nstrata x Nmix matrix of 0/1 elements
  for (j in 1:Nstrata) {
    exch.index[j] ~ dcat(pMix[1:Nmix])
    for (jj in 1:Nmix) {
      exch[j,jj] &lt;- equals(exch.index[j],jj)
    }
  }
  
  # pick theta
  for (j in 1:Nstrata) {
    theta[j] &lt;- LogOdds[exch.index[j],j]
  }
  
  # likelihood part
  for (i in 1:Nstrata) {
    logit( p[i] ) &lt;- theta[i]
    p.success[i]  &lt;- step(p[i]-p.cut)
    r[i] ~ dbin(p[i],n[i])
  }
  
  # un normalized mixture weights
  for (j in 1:Nmix) {
    pMix0[j] ~ dbeta(2, 2)
  }

  for (j in 1:Nmix) {
    pMix[j] &lt;- pMix0[j] / sum(pMix0)
  }

  # predictive part
  for (i in 1:Nstrata) {  
    r_fa[i] ~ dbin(p[i], n_fa[i])
    p.success_fa[i]  &lt;- step(r_fa[i]/n_fa[i]-p.cut)
  }
  
} # end of binary_exnex_model2

write.model(binary_exnex_model2, &#39;binary_exnex_model2.bug&#39;)

### Parameters to monitor
parameters_binary_exnex_model2 &lt;- c(&#39;p&#39;, &#39;pMix&#39;, &#39;p.success&#39;, &#39;p.success_fa&#39;)

### Data
n &lt;- c(&#39;cobi&#39;=20, &#39;atz+bev&#39;=21, &#39;ipat+pac&#39;=19)
r &lt;- c( 5,  3,  3)

## EX part
mu.mean &lt;- c(logit(.05), logit(.15)) # ex prior for hyper meanis centered at logit(0.05)
# ex precision  for hyperpar mean based on (23) of https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf
mu.prec &lt;- 1/sqrt( 1/inv.logit(mu.mean) + 1/(1-inv.logit(mu.mean)) ) # still missing s^2 but this would only make the prior more non-informative
tau.HN.scale &lt;- c(1,1)

## NEX part
nex.mean&lt;-logit(.05) # prior mean for nex part

# prior precision for nex part based on (20) of https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf
nex.prec &lt;- 1/sqrt( 1/inv.logit(nex.mean) + 1/(1-inv.logit(nex.mean)) ) 

p.cut&lt;-.15

pMix&lt;-c(1,0,0)

Nstrata &lt;- n %&gt;% length
Nexch   &lt;- mu.mean %&gt;% length
Nmix    &lt;- Nexch + 1

n_fa &lt;- c(50, 50, 50)

data_binary_exnex_model2 &lt;- list(Nexch=Nexch, Nmix=Nmix, 
                                 Nstrata=Nstrata,
                                 n=n, r=r, n_fa=n_fa,
                                 mu.mean=mu.mean, mu.prec=mu.prec,
                                 tau.HN.scale=tau.HN.scale,
                                 nex.mean=nex.mean, nex.prec=nex.prec, 
                                 p.cut=p.cut
                                )

### Inits
inits_binary_exnex_model2 &lt;- function() {

  list(
    &quot;mu&quot;=rnorm(Nexch),
    &quot;tau&quot;=rnorm(Nexch) %&gt;% abs,
    &quot;pMix0&quot;= rbeta(Nmix, 2, 2)
    )  
} # end of inits_binary_exnex_model

### Run MCMC

# JAGS
set.seed(36)
binary_exnex_jag2 &lt;- jags(data = data_binary_exnex_model2, 
                          inits = inits_binary_exnex_model2, 
                          parameters.to.save = parameters_binary_exnex_model2,
                          model.file = &quot;binary_exnex_model2.bug&quot;,
                          n.chains=3, n.iter=1e4, n.burnin=5e3)</code></pre>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 3
##    Unobserved stochastic nodes: 22
##    Total graph size: 94
## 
## Initializing model</code></pre>
<pre class="r"><code>print(binary_exnex_jag2)</code></pre>
<pre><code>## Inference for Bugs model at &quot;binary_exnex_model2.bug&quot;, fit using jags,
##  3 chains, each with 10000 iterations (first 5000 discarded), n.thin = 5
##  n.sims = 3000 iterations saved
##                 mu.vect sd.vect  2.5%   25%    50%    75%  97.5%  Rhat n.eff
## p[1]              0.223   0.082 0.094 0.161  0.213  0.275  0.403 1.001  3000
## p[2]              0.151   0.069 0.043 0.099  0.144  0.192  0.306 1.001  3000
## p[3]              0.165   0.073 0.048 0.112  0.157  0.210  0.325 1.001  2600
## p.success[1]      0.803   0.398 0.000 1.000  1.000  1.000  1.000 1.001  2200
## p.success[2]      0.472   0.499 0.000 0.000  0.000  1.000  1.000 1.001  3000
## p.success[3]      0.537   0.499 0.000 0.000  1.000  1.000  1.000 1.002  1100
## p.success_fa[1]   0.750   0.433 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success_fa[2]   0.451   0.498 0.000 0.000  0.000  1.000  1.000 1.001  3000
## p.success_fa[3]   0.520   0.500 0.000 0.000  1.000  1.000  1.000 1.001  3000
## pMix[1]           0.335   0.139 0.076 0.239  0.335  0.425  0.620 1.005   740
## pMix[2]           0.363   0.140 0.102 0.268  0.362  0.451  0.654 1.004   660
## pMix[3]           0.302   0.130 0.071 0.206  0.301  0.387  0.581 1.001  3000
## deviance         11.433   2.062 9.059 9.940 10.882 12.343 16.893 1.001  3000
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 2.1 and DIC = 13.6
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="r"><code>binary_exnex_mcmc2 &lt;- binary_exnex_jag2 %&gt;% as.mcmc.rjags
binary_exnex_mcmc2 %&gt;% summary</code></pre>
<pre><code>## 
## Iterations = 1:4996
## Thinning interval = 5 
## Number of chains = 3 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## deviance        11.4330 2.06166 0.037641       0.035902
## p[1]             0.2230 0.08210 0.001499       0.001534
## p[2]             0.1509 0.06875 0.001255       0.001390
## p[3]             0.1650 0.07254 0.001324       0.001405
## p.success[1]     0.8030 0.39780 0.007263       0.007624
## p.success[2]     0.4720 0.49930 0.009116       0.009758
## p.success[3]     0.5370 0.49871 0.009105       0.009254
## p.success_fa[1]  0.7497 0.43328 0.007911       0.008289
## p.success_fa[2]  0.4513 0.49771 0.009087       0.009310
## p.success_fa[3]  0.5200 0.49968 0.009123       0.009124
## pMix[1]          0.3349 0.13892 0.002536       0.002895
## pMix[2]          0.3633 0.13969 0.002550       0.002728
## pMix[3]          0.3018 0.13028 0.002379       0.002640
## 
## 2. Quantiles for each variable:
## 
##                    2.5%     25%     50%     75%   97.5%
## deviance        9.05862 9.93961 10.8820 12.3431 16.8933
## p[1]            0.09384 0.16133  0.2125  0.2746  0.4026
## p[2]            0.04280 0.09879  0.1441  0.1924  0.3062
## p[3]            0.04837 0.11188  0.1568  0.2102  0.3247
## p.success[1]    0.00000 1.00000  1.0000  1.0000  1.0000
## p.success[2]    0.00000 0.00000  0.0000  1.0000  1.0000
## p.success[3]    0.00000 0.00000  1.0000  1.0000  1.0000
## p.success_fa[1] 0.00000 0.00000  1.0000  1.0000  1.0000
## p.success_fa[2] 0.00000 0.00000  0.0000  1.0000  1.0000
## p.success_fa[3] 0.00000 0.00000  1.0000  1.0000  1.0000
## pMix[1]         0.07598 0.23907  0.3352  0.4253  0.6203
## pMix[2]         0.10236 0.26779  0.3617  0.4515  0.6539
## pMix[3]         0.07059 0.20605  0.3012  0.3874  0.5811</code></pre>
<pre class="r"><code>binary_exnex_mcmc2 %&gt;% plot</code></pre>
<p><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-1-1.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-1-2.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-1-3.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-1-4.png" width="672" /></p>
</div>
<div
id="winbugs-model-for-binary-exnex-model-with-fixed-mixture-weights"
class="section level2" number="0.2">
<h2><span class="header-section-number">0.2</span> WinBUGs model for
binary EXNEX model with fixed mixture weights</h2>
<p>This is based on section 5.3 of <a
href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf"
class="uri">https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fpst.1730&amp;file=pst1730-sup-0001-supplementary.pdf</a></p>
<p>Original paper is <a
href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/pst.1730"
class="uri">https://onlinelibrary.wiley.com/doi/epdf/10.1002/pst.1730</a></p>
<pre class="r"><code>### Model definition 
binary_exnex_model &lt;- function() {
## Data to be specify in the input
#-------------------------------------------------------------------------------

# Nexch        - number of exchangeable components
# Nmix         - number of mixture weights and must be Nexch+1
# Nstrata      - number of strata e.g. studies or cohort (in platform trial)
# pMix         - vector of Nmix mixture weights (summing up to 1)
# n            - vector of Nstrata elements storing patient numbers for each stratum
# r            - vector of Nstrata elements storing response numbers for each stratum
# n_fa         - vector of Nstrata elements storing patient numbers for each stratum at final analysis  
# mu.mean      - vector of Nexch prior mean(s)
# mu.prec      - vector of Nexch prior precision(s)
# tau.HN.scale - scale parameter of Half-Normal prior for tau
# nex.mean     - prior mean for non-exchangeable component
# nex.prec     - prior precision for non-exchangeable component
# p.cut        - clinically relevant threshold for response rate to compare against
  
## Parameter(s) to be monitored
# p            - posterior response rate
# p.success    - posterior indicator if p &gt; p.cut
# p.success_fa - posterior indicator if r_fa/n_fa &gt; p.cut
#-------------------------------------------------------------------------------
  
  # prior distributions for EX-parameters
  for (jj in 1:Nexch) {
    mu[jj] ~dnorm(mu.mean[jj],mu.prec[jj])
    prior.tau.prec[jj] &lt;- pow(tau.HN.scale[jj],-2)
    tau[jj] ~ dnorm(0,prior.tau.prec[jj]);I(0.001,)
    prec.tau[jj] &lt;- pow(tau[jj],-2)
  }
  
  # log-odds parameters under EX
  for (jj in 1:Nexch) {
    for (j in 1:Nstrata) {
      re[jj,j] ~ dnorm(0,prec.tau[jj])
      LogOdds[jj,j] &lt;- mu[jj]+re[jj,j]
    }
  }
  
  # log-odds parameters under NEX
  for (j in 1:Nstrata) {
    LogOdds[Nmix,j] ~ dnorm(nex.mean,nex.prec)
  }
  
  # latent mixture indicators:
  # exch.index: categorial 1,...,Nmix=Nexch+1
  # exch: Nstrata x Nmix matrix of 0/1 elements
  for (j in 1:Nstrata) {
    exch.index[j] ~ dcat(pMix[1:Nmix])
    for (jj in 1:Nmix) {
      exch[j,jj] &lt;- equals(exch.index[j],jj)
    }
  }
  
  # pick theta
  for (j in 1:Nstrata) {
    theta[j] &lt;- LogOdds[exch.index[j],j]
  }
  
  # likelihood part
  for (i in 1:Nstrata) {
    logit( p[i] ) &lt;- theta[i]
    p.success[i]  &lt;- step(p[i]-p.cut)
    r[i] ~ dbin(p[i],n[i])
  }

  # predictive part
  for (i in 1:Nstrata) {  
    r_fa[i] ~ dbin(p[i], n_fa[i])
    p.success_fa[i]  &lt;- step(r_fa[i]/n_fa[i]-p.cut)
  }
} # end of binary_exnex_model

write.model(binary_exnex_model, &#39;binary_exnex_model.bug&#39;)

### Parameters to monitor
parameters_binary_exnex_model &lt;- c(&#39;p&#39;, &#39;p.success&#39;, &#39;p.success_fa&#39;)

### Data
data_binary_ex_model &lt;-    list(pMix=c(1,0,0), # full exchangeable
                                Nexch=Nexch, Nmix=Nmix, 
                                Nstrata=Nstrata,
                                n_fa=n_fa, n=n, r=r,
                                mu.mean=mu.mean, mu.prec=mu.prec,
                                tau.HN.scale=tau.HN.scale,
                                nex.mean=nex.mean, nex.prec=nex.prec, p.cut=p.cut
                                )

data_binary_nex_model &lt;-   list(pMix=c(0,0,1), # non-exchangeable
                                Nexch=Nexch, Nmix=Nmix, 
                                Nstrata=Nstrata,
                                n_fa=n_fa, n=n, r=r,
                                mu.mean=mu.mean, mu.prec=mu.prec,
                                tau.HN.scale=tau.HN.scale,
                                nex.mean=nex.mean, nex.prec=nex.prec, p.cut=p.cut
                                )


data_binary_exnex_model &lt;- list(pMix=c(0.5,0,0.5), # exnex
                                Nexch=Nexch, Nmix=Nmix, 
                                Nstrata=Nstrata,
                                n_fa=n_fa, n=n, r=r,
                                mu.mean=mu.mean, mu.prec=mu.prec,
                                tau.HN.scale=tau.HN.scale,
                                nex.mean=nex.mean, nex.prec=nex.prec, p.cut=p.cut
                                )

### Inits
inits_binary_exnex_model &lt;- function() {

  list(
    &quot;mu&quot;=rnorm(Nexch),
    &quot;tau&quot;=rnorm(Nexch) %&gt;% abs
    )  
} # end of inits_binary_exnex_model

### Run MCMC

# JAGS
set.seed(36)
binary_exnex_jag &lt;- jags(data = data_binary_exnex_model, 
                         inits = inits_binary_exnex_model, 
                         parameters.to.save = parameters_binary_exnex_model,
                         model.file = &quot;binary_exnex_model.bug&quot;,
                         n.chains=3, n.iter=1e4, n.burnin=5e3)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 3
##    Unobserved stochastic nodes: 19
##    Total graph size: 89
## 
## Initializing model</code></pre>
<pre class="r"><code>print(binary_exnex_jag)</code></pre>
<pre><code>## Inference for Bugs model at &quot;binary_exnex_model.bug&quot;, fit using jags,
##  3 chains, each with 10000 iterations (first 5000 discarded), n.thin = 5
##  n.sims = 3000 iterations saved
##                 mu.vect sd.vect  2.5%   25%    50%    75%  97.5%  Rhat n.eff
## p[1]              0.217   0.081 0.089 0.158  0.206  0.263  0.403 1.002  1300
## p[2]              0.147   0.067 0.038 0.098  0.138  0.187  0.295 1.001  3000
## p[3]              0.161   0.071 0.045 0.108  0.153  0.204  0.320 1.001  3000
## p.success[1]      0.788   0.409 0.000 1.000  1.000  1.000  1.000 1.001  3000
## p.success[2]      0.433   0.496 0.000 0.000  0.000  1.000  1.000 1.000  3000
## p.success[3]      0.518   0.500 0.000 0.000  1.000  1.000  1.000 1.001  2800
## p.success_fa[1]   0.726   0.446 0.000 0.000  1.000  1.000  1.000 1.001  2700
## p.success_fa[2]   0.445   0.497 0.000 0.000  0.000  1.000  1.000 1.002  1800
## p.success_fa[3]   0.497   0.500 0.000 0.000  0.000  1.000  1.000 1.002  1500
## deviance         11.460   2.214 9.055 9.880 10.838 12.359 17.138 1.001  3000
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 2.5 and DIC = 13.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="r"><code># plot(binary_exnex_jag)

binary_exnex_mcmc &lt;- binary_exnex_jag %&gt;% as.mcmc.rjags
binary_exnex_mcmc %&gt;% summary</code></pre>
<pre><code>## 
## Iterations = 1:4996
## Thinning interval = 5 
## Number of chains = 3 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## deviance        11.4596 2.21374 0.040417       0.045431
## p[1]             0.2166 0.08079 0.001475       0.001857
## p[2]             0.1467 0.06678 0.001219       0.001327
## p[3]             0.1607 0.07089 0.001294       0.001315
## p.success[1]     0.7877 0.40903 0.007468       0.008493
## p.success[2]     0.4333 0.49562 0.009049       0.010160
## p.success[3]     0.5180 0.49976 0.009124       0.009124
## p.success_fa[1]  0.7260 0.44608 0.008144       0.008944
## p.success_fa[2]  0.4447 0.49701 0.009074       0.009653
## p.success_fa[3]  0.4967 0.50007 0.009130       0.008973
## 
## 2. Quantiles for each variable:
## 
##                    2.5%     25%     50%     75%   97.5%
## deviance        9.05542 9.88041 10.8376 12.3592 17.1383
## p[1]            0.08909 0.15777  0.2059  0.2633  0.4032
## p[2]            0.03825 0.09798  0.1379  0.1866  0.2954
## p[3]            0.04494 0.10850  0.1531  0.2043  0.3197
## p.success[1]    0.00000 1.00000  1.0000  1.0000  1.0000
## p.success[2]    0.00000 0.00000  0.0000  1.0000  1.0000
## p.success[3]    0.00000 0.00000  1.0000  1.0000  1.0000
## p.success_fa[1] 0.00000 0.00000  1.0000  1.0000  1.0000
## p.success_fa[2] 0.00000 0.00000  0.0000  1.0000  1.0000
## p.success_fa[3] 0.00000 0.00000  0.0000  1.0000  1.0000</code></pre>
<pre class="r"><code>binary_exnex_mcmc %&gt;% plot</code></pre>
<p><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-1.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-2.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-3.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-4.png" width="672" /></p>
<pre class="r"><code>set.seed(36)
binary_ex_jag &lt;- jags(data = data_binary_ex_model, 
                         inits = inits_binary_exnex_model, 
                         parameters.to.save = parameters_binary_exnex_model,
                         model.file = &quot;binary_exnex_model.bug&quot;,
                         n.chains=3, n.iter=1e4, n.burnin=5e3)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 3
##    Unobserved stochastic nodes: 19
##    Total graph size: 89
## 
## Initializing model</code></pre>
<pre class="r"><code>print(binary_ex_jag)</code></pre>
<pre><code>## Inference for Bugs model at &quot;binary_exnex_model.bug&quot;, fit using jags,
##  3 chains, each with 10000 iterations (first 5000 discarded), n.thin = 5
##  n.sims = 3000 iterations saved
##                 mu.vect sd.vect  2.5%   25%    50%    75%  97.5%  Rhat n.eff
## p[1]              0.200   0.071 0.088 0.149  0.190  0.240  0.370 1.001  3000
## p[2]              0.161   0.059 0.060 0.120  0.156  0.196  0.289 1.001  3000
## p[3]              0.168   0.063 0.065 0.126  0.162  0.204  0.311 1.001  3000
## p.success[1]      0.747   0.435 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success[2]      0.552   0.497 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success[3]      0.582   0.493 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success_fa[1]   0.678   0.467 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success_fa[2]   0.523   0.500 0.000 0.000  1.000  1.000  1.000 1.001  3000
## p.success_fa[3]   0.548   0.498 0.000 0.000  1.000  1.000  1.000 1.001  3000
## deviance         11.041   1.917 9.074 9.766 10.467 11.661 16.256 1.001  2700
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 1.8 and DIC = 12.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="r"><code>binary_ex_mcmc &lt;- binary_ex_jag %&gt;% as.mcmc.rjags
binary_ex_mcmc %&gt;% summary</code></pre>
<pre><code>## 
## Iterations = 1:4996
## Thinning interval = 5 
## Number of chains = 3 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## deviance        11.0414 1.91720 0.035003       0.049395
## p[1]             0.1996 0.07095 0.001295       0.002228
## p[2]             0.1611 0.05905 0.001078       0.001948
## p[3]             0.1685 0.06263 0.001144       0.001339
## p.success[1]     0.7467 0.43499 0.007942       0.011685
## p.success[2]     0.5520 0.49737 0.009081       0.014489
## p.success[3]     0.5817 0.49337 0.009008       0.010287
## p.success_fa[1]  0.6777 0.46745 0.008534       0.010771
## p.success_fa[2]  0.5230 0.49955 0.009121       0.011440
## p.success_fa[3]  0.5483 0.49774 0.009087       0.009090
## 
## 2. Quantiles for each variable:
## 
##                    2.5%    25%     50%     75%   97.5%
## deviance        9.07425 9.7664 10.4667 11.6607 16.2556
## p[1]            0.08776 0.1495  0.1904  0.2402  0.3699
## p[2]            0.06027 0.1205  0.1563  0.1965  0.2891
## p[3]            0.06508 0.1260  0.1619  0.2040  0.3110
## p.success[1]    0.00000 0.0000  1.0000  1.0000  1.0000
## p.success[2]    0.00000 0.0000  1.0000  1.0000  1.0000
## p.success[3]    0.00000 0.0000  1.0000  1.0000  1.0000
## p.success_fa[1] 0.00000 0.0000  1.0000  1.0000  1.0000
## p.success_fa[2] 0.00000 0.0000  1.0000  1.0000  1.0000
## p.success_fa[3] 0.00000 0.0000  1.0000  1.0000  1.0000</code></pre>
<pre class="r"><code>binary_ex_mcmc %&gt;% plot</code></pre>
<p><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-5.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-6.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-7.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-8.png" width="672" /></p>
<pre class="r"><code>set.seed(36)
binary_nex_jag &lt;- jags(data = data_binary_nex_model, 
                         inits = inits_binary_exnex_model, 
                         parameters.to.save = parameters_binary_exnex_model,
                         model.file = &quot;binary_exnex_model.bug&quot;,
                         n.chains=3, n.iter=1e4, n.burnin=5e3)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 3
##    Unobserved stochastic nodes: 19
##    Total graph size: 89
## 
## Initializing model</code></pre>
<pre class="r"><code>print(binary_nex_jag)</code></pre>
<pre><code>## Inference for Bugs model at &quot;binary_exnex_model.bug&quot;, fit using jags,
##  3 chains, each with 10000 iterations (first 5000 discarded), n.thin = 5
##  n.sims = 3000 iterations saved
##                 mu.vect sd.vect  2.5%    25%    50%    75%  97.5%  Rhat n.eff
## p[1]              0.231   0.090 0.082  0.167  0.222  0.286  0.433 1.002  1100
## p[2]              0.134   0.071 0.031  0.080  0.122  0.178  0.293 1.002  3000
## p[3]              0.146   0.076 0.033  0.088  0.136  0.190  0.326 1.002  1900
## p.success[1]      0.814   0.389 0.000  1.000  1.000  1.000  1.000 1.001  3000
## p.success[2]      0.365   0.482 0.000  0.000  0.000  1.000  1.000 1.002  1400
## p.success[3]      0.428   0.495 0.000  0.000  0.000  1.000  1.000 1.001  3000
## p.success_fa[1]   0.762   0.426 0.000  1.000  1.000  1.000  1.000 1.001  3000
## p.success_fa[2]   0.374   0.484 0.000  0.000  0.000  1.000  1.000 1.001  2300
## p.success_fa[3]   0.424   0.494 0.000  0.000  0.000  1.000  1.000 1.001  3000
## deviance         12.074   2.563 9.096 10.207 11.411 13.264 18.445 1.001  2500
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.3 and DIC = 15.4
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="r"><code>binary_nex_mcmc &lt;- binary_nex_jag %&gt;% as.mcmc.rjags
binary_nex_mcmc %&gt;% summary</code></pre>
<pre><code>## 
## Iterations = 1:4996
## Thinning interval = 5 
## Number of chains = 3 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## deviance        12.0739 2.56280 0.046790       0.071097
## p[1]             0.2313 0.08971 0.001638       0.002888
## p[2]             0.1345 0.07124 0.001301       0.002820
## p[3]             0.1465 0.07637 0.001394       0.001440
## p.success[1]     0.8140 0.38917 0.007105       0.010659
## p.success[2]     0.3650 0.48151 0.008791       0.015016
## p.success[3]     0.4277 0.49482 0.009034       0.009134
## p.success_fa[1]  0.7623 0.42572 0.007773       0.010769
## p.success_fa[2]  0.3740 0.48394 0.008836       0.013558
## p.success_fa[3]  0.4237 0.49422 0.009023       0.008678
## 
## 2. Quantiles for each variable:
## 
##                    2.5%      25%     50%     75%   97.5%
## deviance        9.09622 10.20688 11.4112 13.2639 18.4454
## p[1]            0.08171  0.16707  0.2223  0.2858  0.4331
## p[2]            0.03132  0.08005  0.1224  0.1776  0.2925
## p[3]            0.03288  0.08812  0.1361  0.1904  0.3258
## p.success[1]    0.00000  1.00000  1.0000  1.0000  1.0000
## p.success[2]    0.00000  0.00000  0.0000  1.0000  1.0000
## p.success[3]    0.00000  0.00000  0.0000  1.0000  1.0000
## p.success_fa[1] 0.00000  1.00000  1.0000  1.0000  1.0000
## p.success_fa[2] 0.00000  0.00000  0.0000  1.0000  1.0000
## p.success_fa[3] 0.00000  0.00000  0.0000  1.0000  1.0000</code></pre>
<pre class="r"><code>binary_nex_mcmc %&gt;% plot</code></pre>
<p><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-9.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-10.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-11.png" width="672" /><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-2-12.png" width="672" /></p>
</div>
<div
id="credible-interval-for-posterior-distribution-of-true-response-rate"
class="section level2" number="0.3">
<h2><span class="header-section-number">0.3</span> Credible interval for
posterior distribution of “true” response rate</h2>
<pre class="r"><code>### Credible interval for selected parameters
mcmcplots::caterplot(binary_nex_jag, parms = c(&#39;p&#39;), add=F, col=&#39;red&#39;, labels=n%&gt;%names)
mcmcplots::caterplot(binary_exnex_jag2, parms = c(&#39;p&#39;), add=T, cat.shift=.2, labels.loc=F)
mcmcplots::caterplot(binary_ex_jag, parms = c(&#39;p&#39;), add=T, col=&#39;darkgreen&#39;, cat.shift=.4, labels.loc=F)</code></pre>
<p><img src="1_Bouquet_Borrowing_X_Cohort_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
